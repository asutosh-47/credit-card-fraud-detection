{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "11InzoERx1_qm5Huqtzn-ROKhLUzFw9M4",
      "authorship_tag": "ABX9TyNrbNIsDRqPBBALN3OEYpap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armaanranjan/credit-card-fraud-detection/blob/main/CCFD_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Install compatible packages ---\n",
        "!pip install sdv==1.27.0 pandas numpy scikit-learn xgboost matplotlib seaborn -q\n",
        "\n",
        "# --- 2. Import libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    roc_curve, precision_recall_curve\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from google.colab import files\n",
        "\n"
      ],
      "metadata": {
        "id": "P9WrAEHaddSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnjZz-J2c0zI",
        "outputId": "ae9224ab-cd87-4843-f98c-fc3ba02292f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: The file '/content/creditcard.csv' was not found.\n",
            "Please upload the 'creditcard.csv' file to your Colab environment.\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Load Dataset (edit this path) ---\n",
        "# Make sure to upload the creditcard.csv file to your Colab environment\n",
        "# using the file upload button in the left sidebar (folder icon).\n",
        "DATASET_PATH = \"/content/creditcard.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(DATASET_PATH) # Removed encoding and on_bad_lines for standard CSV reading\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(df.head())\n",
        "    print(\"\\nClass Distribution:\\n\", df['Class'].value_counts())\n",
        "\n",
        "    # --- 4. Train CTGAN on Fraud Samples ---\n",
        "\n",
        "    fraud = df[df['Class'] == 1].reset_index(drop=True)\n",
        "\n",
        "    metadata = SingleTableMetadata()\n",
        "    metadata.detect_from_dataframe(data=fraud)\n",
        "    ctgan = CTGANSynthesizer(metadata)\n",
        "    ctgan.fit(fraud)\n",
        "\n",
        "    # --- 5. Generate Synthetic Fraud Samples ---\n",
        "\n",
        "    target_multiplier = 10  # create 10√ó fraud data\n",
        "    n_generate = len(fraud) * target_multiplier\n",
        "    synthetic_fraud = ctgan.sample(num_rows=n_generate)\n",
        "    synthetic_fraud['Class'] = 1\n",
        "\n",
        "    print(f\"\\nGenerated {len(synthetic_fraud)} synthetic fraud samples \")\n",
        "\n",
        "    # --- 6. Create Augmented Dataset ---\n",
        "    augmented_df = pd.concat([df, synthetic_fraud], ignore_index=True).sample(frac=1, random_state=42)\n",
        "    print(\"Augmented class counts:\\n\", augmented_df['Class'].value_counts())\n",
        "\n",
        "    # --- 7. Visualize Class Distribution ---\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.countplot(x='Class', data=augmented_df)\n",
        "    plt.title(\"Class Distribution after GAN Augmentation\")\n",
        "    plt.savefig(\"class_distribution.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # --- 7.5. Clean the Dataset Before Splitting ---\n",
        "\n",
        "    # Remove rows with missing target or any NaN values\n",
        "    augmented_df = augmented_df.dropna(subset=['Class'])\n",
        "    augmented_df = augmented_df.dropna().reset_index(drop=True)\n",
        "\n",
        "    # Ensure target column is integer type (in case it became float after CTGAN)\n",
        "    augmented_df['Class'] = augmented_df['Class'].astype(int)\n",
        "\n",
        "    print(f\" Cleaned dataset ‚Äî no NaN values remain. Final shape: {augmented_df.shape}\")\n",
        "    print(\"Class distribution after cleaning:\\n\", augmented_df['Class'].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # --- 8. Split and Scale Data ---\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        augmented_df.drop(columns=['Class']),\n",
        "        augmented_df['Class'],\n",
        "        test_size=0.2,\n",
        "        stratify=augmented_df['Class'],\n",
        "        random_state=42\n",
        "    )\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # --- 9. Train XGBoost Classifier ---\n",
        "\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # --- 10. Evaluate Model Performance ---\n",
        "\n",
        "    print(\"\\n Classification Report:\\n\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "    plt.plot([0,1],[0,1],'k--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"roc_curve.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Precision‚ÄìRecall Curve\n",
        "    prec, rec, _ = precision_recall_curve(y_test, y_prob)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(rec, prec, color='darkorange')\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision‚ÄìRecall Curve\")\n",
        "    plt.savefig(\"precision_recall_curve.png\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n All visualizations saved: \"\n",
        "          \"class_distribution.png, confusion_matrix.png, roc_curve.png, precision_recall_curve.png\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{DATASET_PATH}' was not found.\")\n",
        "    print(\"Please upload the 'creditcard.csv' file to your Colab environment.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 11. Compare Multiple Classifiers ---\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"Accuracy\": acc}\n",
        "\n",
        "# --- Print Results  ---\n",
        "print(\"Target column used: Class\\n\")\n",
        "for model, metrics in results.items():\n",
        "    print(f\"{model} -> RMSE: {metrics['RMSE']:.2f}, MAE: {metrics['MAE']:.2f}, Accuracy: {metrics['Accuracy']*100:.2f}%\")\n",
        "\n",
        "# --- Convert to DataFrame ---\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "# --- 12. Visual Comparison Graph  ---\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(results_df.index, results_df[\"RMSE\"], color='orange', marker='o', label='RMSE')\n",
        "plt.plot(results_df.index, results_df[\"MAE\"], color='blue', marker='o', label='MAE')\n",
        "plt.title(\"Classifier Performance Comparison (CTGAN-Augmented Fraud Dataset)\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Error Value\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"model_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nComparison chart saved as: model_comparison.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "UNh8yaKGiFbU",
        "outputId": "bb7cfc64-52d5-48be-b7f2-614358ac19d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2773773085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit==1.39.0 pyngrok==7.2.0 xgboost scikit-learn seaborn matplotlib pandas -q\n"
      ],
      "metadata": {
        "id": "zqMwtSMiuELm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Paste your token here ‚Üì\n",
        "!ngrok config add-authtoken 350rMHoVjxDJAOEZKaKEj1itu8U_3UEMgVJ1feVf3PsfU1UfH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au4-gbd6xOze",
        "outputId": "5f52d423-072f-4aa3-e0e3-de473a0828b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üåê Starting Streamlit app ‚Äî please wait a few seconds for the link...\")\n",
        "!streamlit run app.py &>/content/log.txt &\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"‚úÖ Access your GUI here üëá\")\n",
        "print(public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qvpdkbixkjF",
        "outputId": "3ad096ea-7df9-4820-ac5d-488a8d73fb12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Starting Streamlit app ‚Äî please wait a few seconds for the link...\n",
            "‚úÖ Access your GUI here üëá\n",
            "NgrokTunnel: \"https://kimbery-fightable-clotilde.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score,\n",
        "    roc_curve, mean_squared_error, mean_absolute_error, accuracy_score\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "\n",
        "# =========================\n",
        "# Streamlit Config\n",
        "# =========================\n",
        "st.set_page_config(page_title=\"CTGAN + XGBoost Fraud Detection\", layout=\"wide\")\n",
        "st.title(\"üí≥ Credit Card Fraud Detection using CTGAN and XGBoost\")\n",
        "st.write(\"\"\"\n",
        "This system detects fraudulent credit card transactions using **CTGAN for synthetic data generation**\n",
        "and compares multiple classifiers including **XGBoost, Random Forest, Logistic Regression, and KNN.**\n",
        "\"\"\")\n",
        "\n",
        "# =========================\n",
        "# Step 1: Upload Dataset\n",
        "# =========================\n",
        "uploaded_file = st.file_uploader(\"üìÇ Upload credit card dataset (CSV with 'Class' column)\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.subheader(\"üìä Dataset Preview\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "    if 'Class' not in df.columns:\n",
        "        st.error(\"‚ùå The dataset must contain a 'Class' column (0 = normal, 1 = fraud).\")\n",
        "    else:\n",
        "        st.write(\"‚úÖ Original Class Distribution:\")\n",
        "        st.bar_chart(df['Class'].value_counts())\n",
        "\n",
        "        # Variables to store generated data\n",
        "        if \"augmented_df\" not in st.session_state:\n",
        "            st.session_state.augmented_df = None\n",
        "        if \"results_df\" not in st.session_state:\n",
        "            st.session_state.results_df = None\n",
        "        if \"roc_data\" not in st.session_state:\n",
        "            st.session_state.roc_data = None\n",
        "\n",
        "        # =========================\n",
        "        # Step 2: Train CTGAN Button\n",
        "        # =========================\n",
        "        if st.button(\"üß† Train CTGAN and Generate Synthetic Fraud Data\"):\n",
        "            fraud = df[df['Class'] == 1].reset_index(drop=True)\n",
        "            metadata = SingleTableMetadata()\n",
        "            metadata.detect_from_dataframe(data=fraud)\n",
        "\n",
        "            ctgan = CTGANSynthesizer(metadata)\n",
        "            with st.spinner(\"Training CTGAN model... please wait (may take a few minutes)\"):\n",
        "                ctgan.fit(fraud)\n",
        "\n",
        "            target_multiplier = 10\n",
        "            n_generate = len(fraud) * target_multiplier\n",
        "            synthetic_fraud = ctgan.sample(num_rows=n_generate)\n",
        "            synthetic_fraud['Class'] = 1\n",
        "\n",
        "            augmented_df = pd.concat([df, synthetic_fraud], ignore_index=True).sample(frac=1, random_state=42)\n",
        "            st.session_state.augmented_df = augmented_df\n",
        "\n",
        "            st.success(f\"‚úÖ CTGAN trained! Generated {len(synthetic_fraud)} synthetic fraud samples.\")\n",
        "            st.write(\"### üìà Class Distribution After Augmentation\")\n",
        "            st.bar_chart(augmented_df['Class'].value_counts())\n",
        "\n",
        "        # =========================\n",
        "        # Step 3: Train Models Button\n",
        "        # =========================\n",
        "        if st.session_state.augmented_df is not None:\n",
        "            if st.button(\"‚öôÔ∏è Train Classifiers (XGBoost, Random Forest, Logistic Regression, KNN)\"):\n",
        "                augmented_df = st.session_state.augmented_df\n",
        "\n",
        "                X = augmented_df.drop(columns=['Class'])\n",
        "                y = augmented_df['Class']\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "                scaler = StandardScaler()\n",
        "                X_train = scaler.fit_transform(X_train)\n",
        "                X_test = scaler.transform(X_test)\n",
        "\n",
        "                models = {\n",
        "                    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "                    \"Random Forest\": RandomForestClassifier(n_estimators=150, random_state=42),\n",
        "                    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
        "                    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "                }\n",
        "\n",
        "                results = {}\n",
        "                roc_data = {}\n",
        "\n",
        "                with st.spinner(\"Training models...\"):\n",
        "                    for name, clf in models.items():\n",
        "                        clf.fit(X_train, y_train)\n",
        "                        y_pred = clf.predict(X_test)\n",
        "                        y_prob = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else y_pred\n",
        "                        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "                        mae = mean_absolute_error(y_test, y_pred)\n",
        "                        acc = accuracy_score(y_test, y_pred)\n",
        "                        auc = roc_auc_score(y_test, y_prob)\n",
        "                        results[name] = {\"RMSE\": rmse, \"MAE\": mae, \"Accuracy\": acc, \"AUC\": auc}\n",
        "                        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "                        roc_data[name] = (fpr, tpr)\n",
        "\n",
        "                st.session_state.results_df = pd.DataFrame(results).T\n",
        "                st.session_state.roc_data = roc_data\n",
        "                st.success(\"‚úÖ Models trained successfully! You can now view comparisons.\")\n",
        "\n",
        "        # =========================\n",
        "        # Step 4: Show Results Button\n",
        "        # =========================\n",
        "        if st.session_state.results_df is not None and st.button(\"üìä Show Model Comparison Results\"):\n",
        "            results_df = st.session_state.results_df\n",
        "            roc_data = st.session_state.roc_data\n",
        "\n",
        "            st.write(\"### üìã Model Performance Table\")\n",
        "            st.dataframe(results_df.style.highlight_max(color='lightgreen', axis=0))\n",
        "\n",
        "            # Error metrics plot\n",
        "            fig, ax = plt.subplots(figsize=(8, 5))\n",
        "            ax.plot(results_df.index, results_df[\"RMSE\"], marker='o', label='RMSE')\n",
        "            ax.plot(results_df.index, results_df[\"MAE\"], marker='o', label='MAE')\n",
        "            ax.set_title(\"Error Metrics Comparison (CTGAN-Augmented Data)\")\n",
        "            ax.set_xlabel(\"Model\"); ax.set_ylabel(\"Error Value\")\n",
        "            ax.legend(); ax.grid(True)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "            # ROC curves plot\n",
        "            st.write(\"### üìà ROC Curve Comparison\")\n",
        "            fig2, ax2 = plt.subplots(figsize=(7, 5))\n",
        "            for name, (fpr, tpr) in roc_data.items():\n",
        "                ax2.plot(fpr, tpr, label=f\"{name} (AUC={results_df.loc[name, 'AUC']:.3f})\")\n",
        "            ax2.plot([0, 1], [0, 1], 'k--')\n",
        "            ax2.set_xlabel(\"False Positive Rate\")\n",
        "            ax2.set_ylabel(\"True Positive Rate\")\n",
        "            ax2.set_title(\"ROC Curve Comparison\")\n",
        "            ax2.legend()\n",
        "            st.pyplot(fig2)\n",
        "\n",
        "            st.success(\"‚úÖ Model comparison visualized successfully.\")\n",
        "\n",
        "else:\n",
        "    st.info(\"‚¨ÜÔ∏è Upload your anonymized dataset to get started.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XXNXIHMthSN",
        "outputId": "db80d3d2-9ee3-4ce6-d4b8-e70284d2040e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "\n",
        "st.set_page_config(page_title=\"Credit Card Fraud Detection\", layout=\"centered\")\n",
        "st.title(\"üí≥ Credit Card Fraud Detection using CTGAN + XGBoost\")\n",
        "st.write(\"\"\"\n",
        "This demo uses **synthetic, PCA-transformed data** ‚Äî no personal or real card details are used.\n",
        "You can upload an anonymized dataset with a **'Class'** column (0 = Legit, 1 = Fraud).\n",
        "\"\"\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"üìÇ Upload CSV dataset\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.subheader(\"üìä Dataset Preview\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "    if 'Class' not in df.columns:\n",
        "        st.error(\"‚ùå 'Class' column not found ‚Äî please upload a dataset with 'Class' as target.\")\n",
        "    else:\n",
        "        st.write(\"‚úÖ Target column detected:\", df['Class'].value_counts())\n",
        "\n",
        "        if st.button(\"üöÄ Train XGBoost Model\"):\n",
        "            X = df.drop(columns=['Class'])\n",
        "            y = df['Class']\n",
        "\n",
        "            X = X.dropna()\n",
        "            y = y.loc[X.index]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, stratify=y, random_state=42\n",
        "            )\n",
        "            scaler = StandardScaler()\n",
        "            X_train = scaler.fit_transform(X_train)\n",
        "            X_test = scaler.transform(X_test)\n",
        "\n",
        "            model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            st.success(\"‚úÖ Model trained successfully!\")\n",
        "            st.write(\"### üìà Classification Report\")\n",
        "            st.text(classification_report(y_test, y_pred, digits=4))\n",
        "            st.write(f\"ROC-AUC Score = {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "\n",
        "            cm = confusion_matrix(y_test, y_pred)\n",
        "            fig, ax = plt.subplots()\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "            ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
        "            ax.set_title(\"Confusion Matrix\")\n",
        "            st.pyplot(fig)\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "            fig2, ax2 = plt.subplots()\n",
        "            ax2.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "            ax2.plot([0,1],[0,1],'k--')\n",
        "            ax2.set_xlabel(\"False Positive Rate\")\n",
        "            ax2.set_ylabel(\"True Positive Rate\")\n",
        "            ax2.set_title(\"ROC Curve\")\n",
        "            ax2.legend()\n",
        "            st.pyplot(fig2)\n",
        "\n",
        "            st.info(\"‚úÖ Visualizations completed. Model trained on uploaded data successfully.\")\n",
        "else:\n",
        "    st.info(\"‚¨ÜÔ∏è Upload your anonymized credit card dataset to begin.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95Li5i6mbCX1",
        "outputId": "5ff74347-a571-4a1f-c92d-4488fb38a87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}